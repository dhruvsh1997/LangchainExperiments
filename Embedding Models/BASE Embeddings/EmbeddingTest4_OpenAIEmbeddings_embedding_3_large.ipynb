{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WZbV3hrnhopP"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install Required Libraries\n",
        "!pip install -q scikit-learn matplotlib torch transformers sentence-transformers langchain-openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import nltk\n",
        "import re\n",
        "import pandas as pd\n",
        "from scipy.stats import spearmanr\n",
        "import math\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "MAm0Y3IglgdM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY3')"
      ],
      "metadata": {
        "id": "8Hyq0NSr-scX"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Cell 3: Define Utility Functions\n",
        "def simple_clean(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Z630wNWlhld",
        "outputId": "869040f9-b002-4372-ffb0-3f024c0cfe8c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Load Data\n",
        "df = pd.read_excel('/content/synthetic_resume_summaries (1).xlsx')\n",
        "all_texts = df[\"text\"].tolist()\n",
        "all_summaries = df[\"summary\"].tolist()\n",
        "print(f\"Number of samples: {len(all_texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnBrrMWUlsKg",
        "outputId": "5f1b1f08-9cda-49ff-c86d-05069dd0112f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Split Data into Train and Test\n",
        "num_samples = len(all_texts)\n",
        "test_size = 100\n",
        "if num_samples > test_size:\n",
        "    train_indices, test_indices = train_test_split(range(num_samples), test_size=test_size, random_state=42)\n",
        "else:\n",
        "    test_indices = list(range(num_samples))\n",
        "    print(f\"Warning: Number of samples {num_samples} is less than or equal to test_size {test_size}, using all as test.\")\n",
        "print(f\"Train indices: {len(train_indices)}\")\n",
        "print(f\"Test indices: {len(test_indices)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lO4B6KFSluDk",
        "outputId": "080cff9c-68f4-445d-c414-a3ce05dc1efc"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train indices: 900\n",
            "Test indices: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Prepare Corpus and Queries\n",
        "corpus = all_texts\n",
        "queries = [all_summaries[i] for i in test_indices]\n",
        "print(f\"Corpus size: {len(corpus)}\")\n",
        "print(f\"Query size: {len(queries)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNhbrGa5lveE",
        "outputId": "61d08ee5-4f20-42a4-82ef-e26e5fecee9f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus size: 1000\n",
            "Query size: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Encode Corpus and Queries\n",
        "# Initialize tiktoken encoding\n",
        "encoding = tiktoken.get_encoding(\"cl100k_base\")"
      ],
      "metadata": {
        "id": "SO_askNdf3p9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Load Model\n",
        "model_name = \"text-embedding-3-large\"\n",
        "# Cell 7: Load Model\n",
        "embeddings = OpenAIEmbeddings(model=model_name, dimensions=3072)\n",
        "print(f\"Model loaded: {model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MMa2BBUlw1L",
        "outputId": "7a46edda-e127-45c0-f0e3-b66b468c4728"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded: text-embedding-3-large\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process corpus\n",
        "cleaned_corpus = [simple_clean(doc) for doc in corpus]\n",
        "token_counts = [len(encoding.encode(doc)) for doc in cleaned_corpus]"
      ],
      "metadata": {
        "id": "W92U-FVqgkau"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch corpus to keep total tokens < 300,000 per request\n",
        "batches = []\n",
        "current_batch = []\n",
        "current_total = 0\n",
        "max_tokens = 300000\n",
        "\n",
        "for doc, count in zip(cleaned_corpus, token_counts):\n",
        "    if current_total + count > max_tokens:\n",
        "        if current_batch:\n",
        "            batches.append(current_batch)\n",
        "            current_batch = [doc]\n",
        "            current_total = count\n",
        "        else:\n",
        "            # Handle rare case of single doc > max_tokens (unlikely since per-text limit is 8191)\n",
        "            batches.append([doc])\n",
        "            current_total = 0\n",
        "    else:\n",
        "        current_batch.append(doc)\n",
        "        current_total += count\n",
        "if current_batch:\n",
        "    batches.append(current_batch)"
      ],
      "metadata": {
        "id": "E58S6f8Fgoko"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed each batch and collect embeddings\n",
        "corpus_embeddings = []\n",
        "for i, batch in enumerate(batches):\n",
        "    batch_tokens = sum(len(encoding.encode(doc)) for doc in batch)\n",
        "    print(f\"Embedding batch {i+1}/{len(batches)} with {len(batch)} documents, {batch_tokens} tokens\")\n",
        "    batch_embeddings = embeddings.embed_documents(batch)\n",
        "    corpus_embeddings.extend(batch_embeddings)\n",
        "\n",
        "# Process queries (batch if necessary, though likely small)\n",
        "cleaned_queries = [simple_clean(q) for q in queries]\n",
        "query_token_counts = [len(encoding.encode(q)) for q in cleaned_queries]\n",
        "total_query_tokens = sum(query_token_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HC1I495Kgohw",
        "outputId": "30d6b443-97c8-4e6d-a087-9c3b1efe0355"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding batch 1/4 with 334 documents, 298917 tokens\n",
            "Embedding batch 2/4 with 330 documents, 298809 tokens\n",
            "Embedding batch 3/4 with 312 documents, 299198 tokens\n",
            "Embedding batch 4/4 with 24 documents, 19919 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if total_query_tokens > max_tokens:\n",
        "    query_batches = []\n",
        "    current_batch = []\n",
        "    current_total = 0\n",
        "    for q, count in zip(cleaned_queries, query_token_counts):\n",
        "        if current_total + count > max_tokens:\n",
        "            if current_batch:\n",
        "                query_batches.append(current_batch)\n",
        "                current_batch = [q]\n",
        "                current_total = count\n",
        "            else:\n",
        "                query_batches.append([q])\n",
        "                current_total = 0\n",
        "        else:\n",
        "            current_batch.append(q)\n",
        "            current_total += count\n",
        "    if current_batch:\n",
        "        query_batches.append(current_batch)\n",
        "\n",
        "    query_embeddings = []\n",
        "    for i, batch in enumerate(query_batches):\n",
        "        batch_tokens = sum(len(encoding.encode(q)) for q in batch)\n",
        "        print(f\"Embedding query batch {i+1}/{len(query_batches)} with {len(batch)} queries, {batch_tokens} tokens\")\n",
        "        batch_embeddings = embeddings.embed_documents(batch)\n",
        "        query_embeddings.extend(batch_embeddings)\n",
        "else:\n",
        "    print(f\"Embedding {len(cleaned_queries)} queries, {total_query_tokens} tokens\")\n",
        "    query_embeddings = embeddings.embed_documents(cleaned_queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWxdrnNQgoeW",
        "outputId": "611a828f-29dc-4ceb-84f8-934539eef143"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding 100 queries, 15289 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to NumPy arrays\n",
        "corpus_embeddings_np = np.array(corpus_embeddings)\n",
        "query_embeddings_np = np.array(query_embeddings)\n",
        "\n",
        "print(f\"Corpus embeddings shape: {corpus_embeddings_np.shape}\")\n",
        "print(f\"Query embeddings shape: {query_embeddings_np.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW5GKAn4g29O",
        "outputId": "d098688f-5faa-4c45-b0ec-05dd95c2866b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus embeddings shape: (1000, 3072)\n",
            "Query embeddings shape: (100, 3072)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Compute Cosine Similarities\n",
        "similarities = cosine_similarity(query_embeddings_np, corpus_embeddings_np)\n",
        "print(f\"Similarities matrix shape: {similarities.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kuKHbidg25M",
        "outputId": "9dde2430-fb89-4a20-e60c-27496478db35"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarities matrix shape: (100, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Calculate Performance Metrics\n",
        "num_queries = len(queries)\n",
        "mrr_total = 0.0\n",
        "ap_total = 0.0\n",
        "ndcg_total = 0.0\n",
        "top1_correct = 0\n",
        "spearman_total = 0.0\n",
        "\n",
        "for k in range(num_queries):\n",
        "    ranked_indices = np.argsort(similarities[k, :])[::-1]\n",
        "    # MRR\n",
        "    rank = np.where(ranked_indices == test_indices[k])[0]\n",
        "    if len(rank) > 0:\n",
        "        rank = rank[0] + 1\n",
        "        mrr_total += 1.0 / rank\n",
        "    # MAP\n",
        "    sum_prec = 0.0\n",
        "    rel_found = 0\n",
        "    for position, doc_id in enumerate(ranked_indices):\n",
        "        if doc_id == test_indices[k]:\n",
        "            rel_found += 1\n",
        "            sum_prec += rel_found / (position + 1)\n",
        "    if rel_found > 0:\n",
        "        ap = sum_prec / rel_found\n",
        "    else:\n",
        "        ap = 0.0\n",
        "    ap_total += ap\n",
        "    # NDCG\n",
        "    rel = [1 if doc_id == test_indices[k] else 0 for doc_id in ranked_indices]\n",
        "    dcg = sum([rel[i] / math.log2(i + 2) for i in range(len(rel))])\n",
        "    idcg = 1.0 / math.log2(2)\n",
        "    ndcg = dcg / idcg if idcg > 0 else 0.0\n",
        "    ndcg_total += ndcg\n",
        "    # Top-1 Accuracy\n",
        "    if ranked_indices[0] == test_indices[k]:\n",
        "        top1_correct += 1\n",
        "    # Spearman\n",
        "    scores = similarities[k, :]\n",
        "    true_labels = [1 if j == test_indices[k] else 0 for j in range(len(corpus))]\n",
        "    rho, p = spearmanr(scores, true_labels)\n",
        "    if not math.isnan(rho):\n",
        "        spearman_total += rho"
      ],
      "metadata": {
        "id": "Mrzi8hW6lx_j"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mrr = mrr_total / num_queries\n",
        "map_score = ap_total / num_queries\n",
        "average_ndcg = ndcg_total / num_queries\n",
        "accuracy = top1_correct / num_queries\n",
        "average_spearman = spearman_total / num_queries\n",
        "\n",
        "print(\"Performance Summary:\")\n",
        "print(f\"- MRR: {mrr:.4f}\")\n",
        "print(f\"- MAP: {map_score:.4f}\")\n",
        "print(f\"- NDCG: {average_ndcg:.4f}\")\n",
        "print(f\"- Top-1 Accuracy: {accuracy:.4f}\")\n",
        "print(f\"- Average Spearman: {average_spearman:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scseP4mZl42c",
        "outputId": "bda6dd3b-4b22-4f0d-c6b1-79690acd287c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance Summary:\n",
            "- MRR: 0.9574\n",
            "- MAP: 0.9574\n",
            "- NDCG: 0.9669\n",
            "- Top-1 Accuracy: 0.9400\n",
            "- Average Spearman: 0.0546\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o0LLLMbLma1T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}