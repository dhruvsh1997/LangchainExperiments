{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###🌐 UnstructuredHTMLLoader to load HTML content (you can download and use HTML files locally).\n",
        "\n",
        "###🧩 RecursiveCharacterTextSplitter to split the extracted content.\n",
        "\n",
        "###📈 Performance metrics evaluated both for loader and splitter, as per your earlier performance matrix checklist."
      ],
      "metadata": {
        "id": "fTHaJIWUHx3x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Component      | Loader                                      | Splitter                         |\n",
        "| -------------- | ------------------------------------------- | -------------------------------- |\n",
        "| Tool Used      | `UnstructuredHTMLLoader`                    | `RecursiveCharacterTextSplitter` |\n",
        "| Strength       | Handles raw HTML with tag parsing           | Structure-agnostic splitting     |\n",
        "| Weakness       | Doesn’t deeply parse HTML semantic sections | Ignores actual HTML semantics    |\n",
        "| Metrics        | Character count, Token cost, C\\:N ratio     | Chunk CV, Processing speed       |\n",
        "| Coherence Test | Optional STS-B CrossEncoder                 | ✅ Score for continuity           |\n"
      ],
      "metadata": {
        "id": "c8a1lj2hHsX2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj_jfqvlC8Na",
        "outputId": "03763f70-d5f6-446a-bc62-92053f97dce2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# 📘 Notebook: UnstructuredHTMLLoader with RecursiveCharacterTextSplitter\n",
        "# 🧠 Objective: Load an HTML file using UnstructuredHTMLLoader and analyze performance\n",
        "\n",
        "# ✅ Step 1: Install necessary packages\n",
        "!pip install -q langchain unstructured tiktoken psutil transformers langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 2: Import required modules\n",
        "from langchain_community.document_loaders import UnstructuredHTMLLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import requests, time, psutil, os, re\n",
        "import numpy as np\n",
        "import tiktoken"
      ],
      "metadata": {
        "id": "0Uv6VeTtIAnL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 3: Download HTML content from the Wikipedia URL\n",
        "url = \"https://en.wikipedia.org/wiki/Roadside_Picnic\"\n",
        "html_content = requests.get(url).text"
      ],
      "metadata": {
        "id": "IfUdaRkJIKZN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save it locally so BSHTMLLoader can process it\n",
        "with open(\"roadside_picnic.html\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(html_content)"
      ],
      "metadata": {
        "id": "9DlF0cN-IR6w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 3: Load a local HTML file\n",
        "# Please upload your HTML file to the Colab environment (or set correct path)\n",
        "html_path = \"/content/roadside_picnic.html\"  # 🔁 Replace with your HTML file\n",
        "start_time = time.time()\n",
        "process = psutil.Process(os.getpid())\n",
        "initial_mem = process.memory_info().rss / 1024 / 1024\n",
        "loader = UnstructuredHTMLLoader(file_path=html_path)\n",
        "docs = loader.load()\n",
        "end_time = time.time()"
      ],
      "metadata": {
        "id": "wW7UVvqhIZ19"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_mem = process.memory_info().rss / 1024 / 1024\n",
        "\n",
        "# ✅ Step 4: Evaluate Loader Performance Metrics\n",
        "text = \"\\n\".join([doc.page_content for doc in docs])"
      ],
      "metadata": {
        "id": "lxYlIY4SIqQi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tokens(text):\n",
        "    enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "    return len(enc.encode(text))\n",
        "\n",
        "def content_to_noise(text):\n",
        "    alphanum = len(re.findall(r'\\w', text))\n",
        "    total_chars = len(text)\n",
        "    return round(alphanum / total_chars, 4) if total_chars > 0 else 0"
      ],
      "metadata": {
        "id": "9L7OPkSOIsa3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_metrics = {\n",
        "    \"Total Character Count\": len(text),\n",
        "    \"Alphanumeric Character Count\": len(re.findall(r'\\w', text)),\n",
        "    \"Newline Character Count\": text.count(\"\\n\"),\n",
        "    \"Token Count (GPT-4 Encoding)\": count_tokens(text),\n",
        "    \"Content-to-Noise Ratio\": content_to_noise(text),\n",
        "    \"Processing Time (sec)\": round(end_time - start_time, 2),\n",
        "    \"Memory Usage (MB)\": round(final_mem - initial_mem, 2),\n",
        "    \"Structural Preservation\": \"✅ Partial HTML structure (tags) preserved\"\n",
        "}"
      ],
      "metadata": {
        "id": "VXW_xBJvIuv0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"🔍 Loader Performance Metrics (UnstructuredHTMLLoader):\")\n",
        "for k, v in loader_metrics.items():\n",
        "    print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE6CRVqcIv82",
        "outputId": "4011578e-1160-40a4-bf20-8633976a8064"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Loader Performance Metrics (UnstructuredHTMLLoader):\n",
            "Total Character Count: 26470\n",
            "Alphanumeric Character Count: 20980\n",
            "Newline Character Count: 354\n",
            "Token Count (GPT-4 Encoding): 6543\n",
            "Content-to-Noise Ratio: 0.7926\n",
            "Processing Time (sec): 5.78\n",
            "Memory Usage (MB): 326.88\n",
            "Structural Preservation: ✅ Partial HTML structure (tags) preserved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qGFgJcv6IxUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 5: Use RecursiveCharacterTextSplitter to split the text\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=512,\n",
        "    chunk_overlap=50,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")"
      ],
      "metadata": {
        "id": "YoIc5hCNIysz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_start = time.time()\n",
        "split_docs = splitter.split_documents(docs)\n",
        "split_end = time.time()"
      ],
      "metadata": {
        "id": "e0ugVvFFI0e-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = [doc.page_content for doc in split_docs]\n",
        "chunk_lengths = [len(chunk) for chunk in chunks]\n",
        "chunk_tokens = [count_tokens(chunk) for chunk in chunks]\n",
        "\n",
        "def chunk_size_cv(lengths):\n",
        "    mean = np.mean(lengths)\n",
        "    std = np.std(lengths)\n",
        "    return round(std / mean, 4) if mean > 0 else 0"
      ],
      "metadata": {
        "id": "uJ0dFIUeI1pS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_metrics = {\n",
        "    \"Total Chunks\": len(chunks),\n",
        "    \"Avg Chunk Size (chars)\": round(np.mean(chunk_lengths), 2),\n",
        "    \"Chunk Size CV\": chunk_size_cv(chunk_lengths),\n",
        "    \"Token Range\": f\"{min(chunk_tokens)} - {max(chunk_tokens)}\",\n",
        "    \"Processing Speed (MB/s)\": round((len(text)/1024/1024) / (split_end - split_start), 4),\n",
        "    \"Memory Efficiency\": \"✔️ Efficient for plain text extraction\",\n",
        "    \"Metadata Accuracy\": \"❌ No semantic metadata maintained\"\n",
        "}"
      ],
      "metadata": {
        "id": "gIyOX_DkI4jK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n📊 Splitter Performance Metrics (RecursiveCharacterTextSplitter):\")\n",
        "for k, v in split_metrics.items():\n",
        "    print(f\"{k}: {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v2yBu6OI6L1",
        "outputId": "646a3833-966c-4fe1-f283-a9bd1124f552"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Splitter Performance Metrics (RecursiveCharacterTextSplitter):\n",
            "Total Chunks: 74\n",
            "Avg Chunk Size (chars): 369.47\n",
            "Chunk Size CV: 0.4444\n",
            "Token Range: 5 - 197\n",
            "Processing Speed (MB/s): 7.6864\n",
            "Memory Efficiency: ✔️ Efficient for plain text extraction\n",
            "Metadata Accuracy: ❌ No semantic metadata maintained\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oIUtLBYoI7Wb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}