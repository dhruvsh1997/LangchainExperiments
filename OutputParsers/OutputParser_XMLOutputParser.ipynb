{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WH00Enuo9HOE","outputId":"04981553-ef04-4d05-aa53-49caee0ebf14","executionInfo":{"status":"ok","timestamp":1752170061743,"user_tz":-330,"elapsed":10618,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# STEP 1: Install all the necessary libraries.\n","# LangChain for orchestration, LangChain-Groq for Groq LLM.\n","!pip install -q langchain langchain-groq langchain_community"]},{"cell_type":"code","source":["# STEP 2: Gather your spellbooks.\n","from langchain_groq import ChatGroq\n","from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    SystemMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n","    MessagesPlaceholder\n",")\n","from langchain_core.runnables import RunnableWithMessageHistory\n","from langchain_core.chat_history import (\n","    BaseChatMessageHistory,\n","    InMemoryChatMessageHistory\n",")\n","from langchain_core.output_parsers.xml import XMLOutputParser\n","from IPython.display import Markdown, display\n","from google.colab import userdata\n","import os"],"metadata":{"id":"USyLZ7J19KdW","executionInfo":{"status":"ok","timestamp":1752170063789,"user_tz":-330,"elapsed":2032,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# STEP 3: Whisper your secret key to the winds.\n","try:\n","    api_key = userdata.get(\"GROQ_API_KEY\")\n","except Exception:\n","    api_key = os.getenv(\"GROQ_API_KEY\")\n","    if not api_key:\n","        raise ValueError(\"GROQ_API_KEY not found. Please set it!\")\n","\n","# STEP 3b: Summon the Groq-powered LLM.\n","llm = ChatGroq(\n","    model=\"llama-3.3-70b-versatile\",\n","    api_key=api_key,\n","    temperature=0.3,\n",")"],"metadata":{"id":"W7OGJ4Qt-mE4","executionInfo":{"status":"ok","timestamp":1752170065070,"user_tz":-330,"elapsed":1274,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# STEP 4: 📜 Instruct your LLM to always output valid XML.\n","# -----------------------------------------------\n","# ⚡️ CRUCIAL: If you do not explicitly prompt your LLM to respond in valid XML,\n","# XMLOutputParser will fail because it expects well-formed XML!\n","# -----------------------------------------------\n","\n","system_msg = SystemMessagePromptTemplate.from_template(\n","    \"You are an XML generator assistant. Always respond in well-formed XML with <response> root tag.\"\n",")\n","\n","human_msg = HumanMessagePromptTemplate.from_template(\n","    \"{input}\"\n",")\n","\n","chat_prompt = ChatPromptTemplate.from_messages([\n","    system_msg,\n","    MessagesPlaceholder(variable_name=\"history\"),\n","    human_msg\n","])"],"metadata":{"id":"M-R0USD4-ptk","executionInfo":{"status":"ok","timestamp":1752170065120,"user_tz":-330,"elapsed":24,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# STEP 5: Archive the echoes of your conversations.\n","store = {}\n","\n","def get_session_history(session_id: str) -> BaseChatMessageHistory:\n","    if session_id not in store:\n","        store[session_id] = InMemoryChatMessageHistory()\n","    return store[session_id]"],"metadata":{"id":"8WOuoGe3-sON","executionInfo":{"status":"ok","timestamp":1752170065176,"user_tz":-330,"elapsed":53,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# STEP 6: 🗝️ The heart of this spell!\n","# -----------------------------------------------\n","# 💡 XMLOutputParser expects valid XML and parses it into ElementTree.\n","# It will raise an error if the LLM’s output is not valid XML.\n","# So your prompt must always guide the LLM carefully.\n","# -----------------------------------------------\n","\n","chat_chain = chat_prompt | llm\n","\n","# Add the XML parser\n","parsed_chain = chat_chain | XMLOutputParser()\n","\n","# Do NOT attach XMLOutputParser inside the chain\n","chat_chain = chat_prompt | llm\n","\n","# Wrap with memory support\n","chatbot = RunnableWithMessageHistory(\n","    chat_chain,  # << Just raw LLM\n","    get_session_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"history\"\n",")"],"metadata":{"id":"ca6OqbP6-tqf","executionInfo":{"status":"ok","timestamp":1752170065235,"user_tz":-330,"elapsed":55,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import xml.etree.ElementTree as ET\n","\n","session_id = \"chat-session-xml-001\"\n","\n","user_inputs = [\n","    \"Describe the confusion matrix in an XML format with fields <answer> and <source>.\",\n","    \"Give an example of precision and recall wrapped in <answer> and <source>.\"\n","]\n","\n","print(f\"Starting chat loop with session ID: {session_id}\")\n","\n","for input_text in user_inputs:\n","    print(f\"\\nUser: {input_text}\")\n","    raw_response = chatbot.invoke(\n","        {\"input\": input_text},\n","        config={\"configurable\": {\"session_id\": session_id}}\n","    )\n","    print(\"Raw Response:\", raw_response)\n","\n","    # ✅ FIX: Access the content string!\n","    response_tree = ET.fromstring(raw_response.content)\n","\n","    answer = response_tree.find(\"answer\").text if response_tree.find(\"answer\") is not None else \"No <answer> found\"\n","    source = response_tree.find(\"source\").text if response_tree.find(\"source\") is not None else \"No <source> found\"\n","    display(Markdown(f\"**Answer:** {answer}\\n\\n**Source:** {source}\"))\n","\n","print(\"\\n--- Stored Chat History ---\")\n","for message in store[session_id].messages:\n","    print(f\"{message.type.capitalize()}: {message.content}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"IYgrMzmH-vCX","outputId":"deb7aec8-7e78-4daa-e6c6-b9092d32fb64","executionInfo":{"status":"ok","timestamp":1752170190845,"user_tz":-330,"elapsed":1908,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting chat loop with session ID: chat-session-xml-001\n","\n","User: Describe the confusion matrix in an XML format with fields <answer> and <source>.\n","Raw Response: content='<response>\\n  <answer>\\n    The confusion matrix is a table that is used to describe the performance of a classification model, such as a logistic regression or decision tree, against a test dataset. \\n    The matrix itself is relatively simple to understand, but the related terminology can be confusing. \\n    The matrix has the following structure:\\n    - True Positives (TP): These are the correctly predicted positive values.\\n    - True Negatives (TN): These are the correctly predicted negative values.\\n    - False Positives (FP): These are the incorrectly predicted positive values.\\n    - False Negatives (FN): These are the incorrectly predicted negative values.\\n  </answer>\\n  <source>Wikipedia, Machine Learning documentation, and various academic papers on classification models and model evaluation metrics.</source>\\n</response>' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 165, 'prompt_tokens': 228, 'total_tokens': 393, 'completion_time': 0.547737869, 'prompt_time': 0.011405165, 'queue_time': 0.225147385, 'total_time': 0.559143034}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None} id='run--319552df-64ca-4abf-9f66-5fdc3fe4fa24-0' usage_metadata={'input_tokens': 228, 'output_tokens': 165, 'total_tokens': 393}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Answer:** \n    The confusion matrix is a table that is used to describe the performance of a classification model, such as a logistic regression or decision tree, against a test dataset. \n    The matrix itself is relatively simple to understand, but the related terminology can be confusing. \n    The matrix has the following structure:\n    - True Positives (TP): These are the correctly predicted positive values.\n    - True Negatives (TN): These are the correctly predicted negative values.\n    - False Positives (FP): These are the incorrectly predicted positive values.\n    - False Negatives (FN): These are the incorrectly predicted negative values.\n  \n\n**Source:** Wikipedia, Machine Learning documentation, and various academic papers on classification models and model evaluation metrics."},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","User: Give an example of precision and recall wrapped in <answer> and <source>.\n","Raw Response: content='<response>\\n  <answer>\\n    Precision and recall are two important metrics used to evaluate the performance of a classification model. \\n    Precision is the ratio of True Positives (TP) to the sum of True Positives (TP) and False Positives (FP), i.e., Precision = TP / (TP + FP). \\n    Recall is the ratio of True Positives (TP) to the sum of True Positives (TP) and False Negatives (FN), i.e., Recall = TP / (TP + FN).\\n    For example, suppose we have a model that predicts whether a person has a disease or not, and we get the following results:\\n    - True Positives (TP): 80 (correctly predicted to have the disease)\\n    - True Negatives (TN): 700 (correctly predicted to not have the disease)\\n    - False Positives (FP): 20 (incorrectly predicted to have the disease)\\n    - False Negatives (FN): 10 (incorrectly predicted to not have the disease)\\n    Then, Precision = 80 / (80 + 20) = 0.8 and Recall = 80 / (80 + 10) = 0.889.\\n  </answer>\\n  <source>Wikipedia, Machine Learning documentation, and various academic papers on classification models and model evaluation metrics, such as the scikit-learn documentation and the book \"Pattern Recognition and Machine Learning\" by Christopher Bishop.</source>\\n</response>' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 306, 'prompt_tokens': 418, 'total_tokens': 724, 'completion_time': 0.609187478, 'prompt_time': 0.02127848, 'queue_time': 0.22506831100000002, 'total_time': 0.630465958}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_3f3b593e33', 'finish_reason': 'stop', 'logprobs': None} id='run--7e6bf47a-9983-492b-94a3-eb9ee8c21f28-0' usage_metadata={'input_tokens': 418, 'output_tokens': 306, 'total_tokens': 724}\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Answer:** \n    Precision and recall are two important metrics used to evaluate the performance of a classification model. \n    Precision is the ratio of True Positives (TP) to the sum of True Positives (TP) and False Positives (FP), i.e., Precision = TP / (TP + FP). \n    Recall is the ratio of True Positives (TP) to the sum of True Positives (TP) and False Negatives (FN), i.e., Recall = TP / (TP + FN).\n    For example, suppose we have a model that predicts whether a person has a disease or not, and we get the following results:\n    - True Positives (TP): 80 (correctly predicted to have the disease)\n    - True Negatives (TN): 700 (correctly predicted to not have the disease)\n    - False Positives (FP): 20 (incorrectly predicted to have the disease)\n    - False Negatives (FN): 10 (incorrectly predicted to not have the disease)\n    Then, Precision = 80 / (80 + 20) = 0.8 and Recall = 80 / (80 + 10) = 0.889.\n  \n\n**Source:** Wikipedia, Machine Learning documentation, and various academic papers on classification models and model evaluation metrics, such as the scikit-learn documentation and the book \"Pattern Recognition and Machine Learning\" by Christopher Bishop."},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","--- Stored Chat History ---\n","Human: Describe the confusion matrix in an XML format with fields <answer> and <source>.\n","Ai: <response>\n","  <answer>The confusion matrix is a table used to evaluate the performance of a classification model. It has four main components: True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN). The matrix is used to calculate various metrics such as accuracy, precision, recall, and F1 score, which help in understanding the model's performance.</answer>\n","  <source>The concept of the confusion matrix is widely used in machine learning and data science, and is often referenced in academic papers and online resources, including Wikipedia and scikit-learn documentation.</source>\n","</response>\n","Human: Describe the confusion matrix in an XML format with fields <answer> and <source>.\n","Ai: <response>\n","  <answer>\n","    The confusion matrix is a table that is used to describe the performance of a classification model, such as a logistic regression or decision tree, against a test dataset. \n","    The matrix itself is relatively simple to understand, but the related terminology can be confusing. \n","    The matrix has the following structure:\n","    - True Positives (TP): These are the correctly predicted positive values.\n","    - True Negatives (TN): These are the correctly predicted negative values.\n","    - False Positives (FP): These are the incorrectly predicted positive values.\n","    - False Negatives (FN): These are the incorrectly predicted negative values.\n","  </answer>\n","  <source>Wikipedia, Machine Learning documentation, and various academic papers on classification models and model evaluation metrics.</source>\n","</response>\n","Human: Give an example of precision and recall wrapped in <answer> and <source>.\n","Ai: <response>\n","  <answer>\n","    Precision and recall are two important metrics used to evaluate the performance of a classification model. \n","    Precision is the ratio of True Positives (TP) to the sum of True Positives (TP) and False Positives (FP), i.e., Precision = TP / (TP + FP). \n","    Recall is the ratio of True Positives (TP) to the sum of True Positives (TP) and False Negatives (FN), i.e., Recall = TP / (TP + FN).\n","    For example, suppose we have a model that predicts whether a person has a disease or not, and we get the following results:\n","    - True Positives (TP): 80 (correctly predicted to have the disease)\n","    - True Negatives (TN): 700 (correctly predicted to not have the disease)\n","    - False Positives (FP): 20 (incorrectly predicted to have the disease)\n","    - False Negatives (FN): 10 (incorrectly predicted to not have the disease)\n","    Then, Precision = 80 / (80 + 20) = 0.8 and Recall = 80 / (80 + 10) = 0.889.\n","  </answer>\n","  <source>Wikipedia, Machine Learning documentation, and various academic papers on classification models and model evaluation metrics, such as the scikit-learn documentation and the book \"Pattern Recognition and Machine Learning\" by Christopher Bishop.</source>\n","</response>\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CaRtS75yDdJF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RZTdtO3FDdGS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H5PAdDEcDdDa"},"execution_count":null,"outputs":[]}]}