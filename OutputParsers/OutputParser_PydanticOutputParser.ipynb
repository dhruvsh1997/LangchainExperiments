{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMYXl4kCY38U0mdklgXDGYL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# +----------------+\n","# |  Input Prompt  |\n","# +----------------+\n","#         |\n","#         v\n","# +----------------+\n","# |      LLM       |\n","# +----------------+\n","#         |\n","#         v\n","# +--------------------------+\n","# | PydanticOutputParser     |\n","# | (Validate + parse)       |\n","# +--------------------------+\n","#         |\n","#         v\n","# +--------------------------+\n","# |  Python Pydantic Object  |\n","# +--------------------------+"],"metadata":{"id":"POhZDDEmCW6S","executionInfo":{"status":"ok","timestamp":1752515062966,"user_tz":-330,"elapsed":14,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzg-ZxZWAsT8","executionInfo":{"status":"ok","timestamp":1752515095866,"user_tz":-330,"elapsed":14393,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}},"outputId":"678dc976-175a-43a2-e669-6b6bcf4025a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.9/2.5 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# STEP 1: Install the essentials\n","!pip install -q langchain langchain-groq langchain_community pydantic"]},{"cell_type":"code","source":["# STEP 2: Gather your spellbooks\n","from langchain_groq import ChatGroq\n","from langchain.prompts.chat import (\n","    ChatPromptTemplate,\n","    SystemMessagePromptTemplate,\n","    HumanMessagePromptTemplate,\n","    MessagesPlaceholder\n",")\n","from langchain_core.runnables import RunnableWithMessageHistory\n","from langchain_core.chat_history import (\n","    BaseChatMessageHistory,\n","    InMemoryChatMessageHistory\n",")\n","from langchain_core.output_parsers.pydantic import PydanticOutputParser\n","from pydantic import BaseModel, Field\n","from IPython.display import Markdown, display\n","from google.colab import userdata\n","import os"],"metadata":{"id":"o94h2EBeA8Ax","executionInfo":{"status":"ok","timestamp":1752515096915,"user_tz":-330,"elapsed":1020,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# STEP 3: Whisper your secret key to the winds\n","try:\n","    api_key = userdata.get(\"GROQ_API_KEY\")\n","except Exception:\n","    api_key = os.getenv(\"GROQ_API_KEY\")\n","    if not api_key:\n","        raise ValueError(\"GROQ_API_KEY not found. Please set it!\")\n","\n","llm = ChatGroq(\n","    model=\"llama-3.3-70b-versatile\",\n","    api_key=api_key,\n","    temperature=0.3,\n",")"],"metadata":{"id":"8RwyeamNA79p","executionInfo":{"status":"ok","timestamp":1752515118840,"user_tz":-330,"elapsed":1299,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# STEP 4: Craft the Pydantic schema that your LLM must respect.\n","# -------------------------------------------------------------\n","# This model defines the expected output.\n","# The Output Parser will check that the LLM output matches this schema.\n","# -------------------------------------------------------------\n","\n","class ConfusionMatrixExplanation(BaseModel):\n","    answer: str = Field(..., description=\"Explanation of what a confusion matrix is.\")\n","    source: str = Field(..., description=\"Where this information came from.\")"],"metadata":{"id":"bx5grp3oA76m","executionInfo":{"status":"ok","timestamp":1752515118855,"user_tz":-330,"elapsed":13,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# STEP 5: Summon the PydanticOutputParser with your model.\n","# It will enforce validation automatically.\n","parser = PydanticOutputParser(pydantic_object=ConfusionMatrixExplanation)"],"metadata":{"id":"YQYTxrbFA73N","executionInfo":{"status":"ok","timestamp":1752515174168,"user_tz":-330,"elapsed":32,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# STEP 6: This is CRUCIAL.\n","# -------------------------------------------------------------\n","# You MUST tell your LLM how to format its output to match the Pydantic schema.\n","# The parser provides a format_instructions string you can inject in your prompt.\n","# -------------------------------------------------------------\n","\n","# Get the format instructions\n","format_instructions = parser.get_format_instructions()\n","\n","# Put a placeholder\n","system_msg = SystemMessagePromptTemplate.from_template(\n","    \"You are a helpful assistant. Please format your response to match these instructions:\\n{format_instructions}\"\n",")\n","\n","human_msg = HumanMessagePromptTemplate.from_template(\n","    \"{input}\"\n",")\n","\n","# Compose the chat prompt\n","chat_prompt = ChatPromptTemplate.from_messages([\n","    system_msg,\n","    MessagesPlaceholder(variable_name=\"history\"),\n","    human_msg\n","])\n","\n","# Supply the format_instructions as partial\n","chat_prompt = chat_prompt.partial(format_instructions=format_instructions)"],"metadata":{"id":"EBXakAejA70D","executionInfo":{"status":"ok","timestamp":1752516003146,"user_tz":-330,"elapsed":7,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# STEP 7: Keep your memories safe.\n","store = {}\n","\n","def get_session_history(session_id: str) -> BaseChatMessageHistory:\n","    if session_id not in store:\n","        store[session_id] = InMemoryChatMessageHistory()\n","    return store[session_id]"],"metadata":{"id":"FHphITDbA7xN","executionInfo":{"status":"ok","timestamp":1752516004115,"user_tz":-330,"elapsed":6,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# STEP 8: Combine your chain.\n","# -------------------------------------------------------------\n","# ⚡ IMPORTANT: Using PydanticOutputParser in the chain means the output will be a Pydantic model.\n","# The memory will store raw text.\n","# -------------------------------------------------------------\n","chat_chain = chat_prompt | llm | parser\n","\n","# Wrap it with memory support\n","chatbot = RunnableWithMessageHistory(\n","    chat_chain,\n","    get_session_history,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"history\"\n",")"],"metadata":{"id":"cVWH1ar6A7t2","executionInfo":{"status":"ok","timestamp":1752516004884,"user_tz":-330,"elapsed":5,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# STEP 9: Test it!\n","session_id = \"chat-session-pydantic-001\"\n","\n","user_inputs = [\n","    \"Explain what a confusion matrix is with a short source reference.\",\n","    \"Now explain what precision and recall are, and cite any source.\"\n","]\n","\n","print(f\"Starting chat loop with session ID: {session_id}\")\n","\n","for input_text in user_inputs:\n","    print(f\"\\nUser: {input_text}\")\n","    response_model = chatbot.invoke(\n","        {\"input\": input_text},\n","        config={\"configurable\": {\"session_id\": session_id}}\n","    )\n","    # This is your validated Pydantic object!\n","    display(Markdown(f\"**Answer:** {response_model.answer}\\n\\n**Source:** {response_model.source}\"))\n","\n","print(\"\\n--- Stored Chat History ---\")\n","for message in store[session_id].messages:\n","    print(f\"{message.type.capitalize()}: {message.content}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":395},"id":"pzpNusjQA7qP","executionInfo":{"status":"ok","timestamp":1752516007122,"user_tz":-330,"elapsed":1390,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}},"outputId":"06a1dd25-c287-43ce-cc4f-d5d185c1846b"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["Starting chat loop with session ID: chat-session-pydantic-001\n","\n","User: Explain what a confusion matrix is with a short source reference.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.callbacks.manager:Error in RootListenersTracer.on_chain_end callback: ValueError(\"Expected str, BaseMessage, list[BaseMessage], or tuple[BaseMessage]. Got answer='A confusion matrix is a table used to evaluate the performance of a classification model, where the true classes are compared against the predicted classes, allowing for the calculation of metrics such as accuracy, precision, and recall.' source='Wikipedia - Confusion Matrix'.\")\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Answer:** A confusion matrix is a table used to evaluate the performance of a classification model, where the true classes are compared against the predicted classes, allowing for the calculation of metrics such as accuracy, precision, and recall.\n\n**Source:** Wikipedia - Confusion Matrix"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","User: Now explain what precision and recall are, and cite any source.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:langchain_core.callbacks.manager:Error in RootListenersTracer.on_chain_end callback: ValueError('Expected str, BaseMessage, list[BaseMessage], or tuple[BaseMessage]. Got answer=\"Precision and recall are two fundamental metrics used to evaluate the performance of a classification model. Precision is the ratio of true positives (correctly predicted instances) to the sum of true positives and false positives (incorrectly predicted instances). It measures the accuracy of the model\\'s positive predictions. Recall, on the other hand, is the ratio of true positives to the sum of true positives and false negatives (missed instances). It measures the model\\'s ability to detect all instances of a particular class. In other words, precision answers the question \\'How many of the predicted instances are actually positive?\\' while recall answers \\'How many of the actual positive instances were predicted?\\'\" source=\\'https://en.wikipedia.org/wiki/Precision_and_recall\\'.')\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**Answer:** Precision and recall are two fundamental metrics used to evaluate the performance of a classification model. Precision is the ratio of true positives (correctly predicted instances) to the sum of true positives and false positives (incorrectly predicted instances). It measures the accuracy of the model's positive predictions. Recall, on the other hand, is the ratio of true positives to the sum of true positives and false negatives (missed instances). It measures the model's ability to detect all instances of a particular class. In other words, precision answers the question 'How many of the predicted instances are actually positive?' while recall answers 'How many of the actual positive instances were predicted?'\n\n**Source:** https://en.wikipedia.org/wiki/Precision_and_recall"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","--- Stored Chat History ---\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"QHayN6jaA7nZ","executionInfo":{"status":"ok","timestamp":1752516011220,"user_tz":-330,"elapsed":34,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"70y4jEWQA7kf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"JAyuACSLA7hl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"T7yHHm_jA7e7"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a8cc1b58"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ce0e2985"},"source":[],"execution_count":null,"outputs":[]}]}