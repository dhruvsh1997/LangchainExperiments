{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What is an Output Parser in LangChain?<br>\n",
        "In the grand tapestry of LLMs, an Output Parser is the bridge between the raw, untamed text generated by your model and the structured, machine-usable format you crave.<br>\n",
        "It’s your loyal scribe, your formatter, your rule-keeper:<br>\n",
        "1. It interprets the raw output into Python data types (strings, lists, dicts).\n",
        "2. It validates that the format matches what you expect.\n",
        "3. It enables you to chain LLMs with other tools that need structured input.\n",
        "<br>In essence, Output Parsers make your pipeline robust and reliable, ensuring the song the LLM sings can be orchestrated into downstream tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "e2I1DeDs7XSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What types of Output Parsers does LangChain offer?<br>\n",
        "LangChain is a veritable garden of parsers, each blooming for different scenarios:<br>\n",
        "1. StrOutputParser: the simplest. It takes the raw text as a string.\n",
        "2. RegexOutputParser: matches specific patterns using regular expressions.\n",
        "3. PydanticOutputParser: parses output into structured Pydantic models for strict validation.\n",
        "4. JSONOutputParser: ensures the output is valid JSON and parses it to a Python dict.\n",
        "5. DataclassOutputParser: uses Python dataclasses instead of Pydantic.\n",
        "<br>Each one is a brushstroke, shaping the raw clay of language into forms you can wield.\n",
        "\n"
      ],
      "metadata": {
        "id": "QrH-SA2u7h55"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "detM0A__7VKD",
        "outputId": "abde2bbd-3b1c-41d5-b97e-4a31fbda0ffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# STEP 1: Install all the necessary libraries.\n",
        "# LangChain for orchestration, LangChain-Groq for Groq LLM.\n",
        "!pip install -q langchain langchain-groq langchain_community"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers.json import JsonOutputParser"
      ],
      "metadata": {
        "id": "jU1iwjHU-RPS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Gather all the wands and scrolls we shall need.\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory # <--- CORRECTED IMPORT\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from IPython.display import Markdown, display\n",
        "from google.colab import userdata\n",
        "import os"
      ],
      "metadata": {
        "id": "aAQiHYBP7vg_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Whisper your secret key to the winds.\n",
        "try:\n",
        "    api_key = userdata.get(\"GROQ_API_KEY\")\n",
        "except Exception:\n",
        "    api_key = os.getenv(\"GROQ_API_KEY\")\n",
        "    if not api_key:\n",
        "        raise ValueError(\"GROQ_API_KEY not found. Please set it!\")\n",
        "\n",
        "# STEP 3b: Summon the Groq-powered LLM.\n",
        "llm = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\",\n",
        "    api_key=api_key,\n",
        "    temperature=0.3,\n",
        ")"
      ],
      "metadata": {
        "id": "AhqjAjMU70oR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Craft the conversation spell.\n",
        "# This prompt template will guide your LLM's responses.\n",
        "system_msg = SystemMessagePromptTemplate.from_template(\n",
        "    \"You are a friendly, knowledgeable assistant. Answer user queries clearly and remember previous interactions.\"\n",
        ")\n",
        "\n",
        "# The MessagesPlaceholder enables your memory to weave old threads into new responses.\n",
        "human_msg = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    system_msg,\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    human_msg\n",
        "])"
      ],
      "metadata": {
        "id": "R2f7oyTy72wL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: Store memories like a faithful archivist.\n",
        "# Using a simple dictionary and in-memory chat history.\n",
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryChatMessageHistory()\n",
        "    return store[session_id]"
      ],
      "metadata": {
        "id": "MxbMQDOD8nvn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Here enters the StrOutputParser!\n",
        "# ----------------------------\n",
        "# WHAT IT DOES: This parser simply returns the raw LLM output as a plain string.\n",
        "# Use it when you want to keep things simple — just text, no fancy structure.\n",
        "# ----------------------------\n",
        "\n",
        "# First, combine the prompt and the LLM.\n",
        "chat_chain = chat_prompt | llm\n",
        "\n",
        "# Now add the StrOutputParser at the end.\n",
        "# The `|` operator chains the steps.\n",
        "parsed_chain = chat_chain | StrOutputParser()\n",
        "\n",
        "# Wrap this parsed chain with message history so it remembers context.\n",
        "chatbot = RunnableWithMessageHistory(\n",
        "    parsed_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\"\n",
        ")"
      ],
      "metadata": {
        "id": "xd1Ia28e8pfL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: Dance the dance — start chatting and see how your StrOutputParser works.\n",
        "# The parser ensures that you always get clean, simple strings back.\n",
        "\n",
        "session_id = \"chat-session-001\"\n",
        "\n",
        "# A few questions to test your chain.\n",
        "user_inputs = [\n",
        "    \"Hi! What is an output parser in LangChain?\",\n",
        "    \"Why would I use StrOutputParser specifically?\",\n",
        "    \"Are there other types of parsers? How are they different?\"\n",
        "]\n",
        "\n",
        "print(f\"Starting chat loop with session ID: {session_id}\")\n",
        "\n",
        "for input_text in user_inputs:\n",
        "    print(f\"\\nUser: {input_text}\")\n",
        "    response = chatbot.invoke(\n",
        "        {\"input\": input_text},\n",
        "        config={\"configurable\": {\"session_id\": session_id}}\n",
        "    )\n",
        "    # You will see plain strings thanks to StrOutputParser.\n",
        "    display(Markdown(f\"**Assistant:** {response}\"))\n",
        "\n",
        "# See what your memory has preserved.\n",
        "print(\"\\n--- Stored Chat History ---\")\n",
        "for message in store[session_id].messages:\n",
        "    print(f\"{message.type.capitalize()}: {message.content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NYOCiS_w8sM_",
        "outputId": "bea9e532-6ca6-4d53-e39c-bdbe0ea0e701"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting chat loop with session ID: chat-session-001\n",
            "\n",
            "User: Hi! What is an output parser in LangChain?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:** In LangChain, an output parser is a crucial component that helps extract relevant information from the output of a language model (LLM) or other AI tools. \n\nThe primary function of an output parser is to take the raw output from an LLM, which can be unstructured or semi-structured text, and convert it into a more structured and usable format. This can include extracting specific entities, such as names, dates, or keywords, or identifying particular patterns or relationships within the text.\n\nOutput parsers in LangChain are typically designed to be flexible and customizable, allowing developers to define their own parsing rules and logic to suit specific use cases or applications. By using output parsers, developers can more easily integrate LLMs into larger workflows or systems, and unlock the full potential of these powerful AI tools.\n\nWould you like to know more about how output parsers are used in LangChain or how to implement them in your own projects?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: Why would I use StrOutputParser specifically?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:** The `StrOutputParser` is a specific type of output parser in LangChain, and it's designed to parse string outputs from language models.\n\nYou would use `StrOutputParser` when you want to extract information from a string output, such as a piece of text, a sentence, or a short paragraph. This parser is particularly useful when you need to:\n\n1. **Extract specific substrings**: For example, you might want to extract a specific keyword, phrase, or identifier from the output string.\n2. **Apply regular expressions**: `StrOutputParser` allows you to use regular expressions to match patterns in the output string, making it easy to extract complex information.\n3. **Split or tokenize the output**: You can use `StrOutputParser` to split the output string into individual tokens, such as words or phrases, which can be useful for further processing or analysis.\n\nThe `StrOutputParser` is a simple yet powerful tool for extracting insights from string outputs. It's often used in conjunction with other LangChain components, such as agents or prompts, to build more complex workflows and applications.\n\nIs there a specific use case you're considering for `StrOutputParser`, or would you like more information on how to use it in your projects?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: Are there other types of parsers? How are they different?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Assistant:** In LangChain, there are several types of output parsers, each designed to handle different types of output data. Here are some examples:\n\n1. **StrOutputParser**: As we discussed earlier, this parser is designed to handle string outputs, such as text, sentences, or paragraphs.\n2. **JsonOutputParser**: This parser is used to handle JSON (JavaScript Object Notation) outputs, which are commonly used in web development and data exchange. `JsonOutputParser` allows you to extract specific data from JSON objects, such as keys, values, or nested structures.\n3. **DictOutputParser**: This parser is similar to `JsonOutputParser`, but it's designed to handle Python dictionaries (also known as dicts) instead of JSON objects. `DictOutputParser` is useful when working with outputs that are already in a dictionary format.\n4. **ListOutputParser**: As the name suggests, this parser is designed to handle list outputs, such as arrays of values or collections of items. `ListOutputParser` allows you to extract specific elements from the list, filter the list, or perform other operations.\n\nThe main difference between these parsers is the type of output data they're designed to handle. Each parser has its own set of features and capabilities, tailored to the specific characteristics of the output data.\n\nWhen choosing a parser, consider the format and structure of the output data you're working with. For example:\n\n* If you're working with text outputs, `StrOutputParser` is a good choice.\n* If you're working with JSON data, `JsonOutputParser` is a better fit.\n* If you're working with Python dictionaries, `DictOutputParser` is the way to go.\n\nBy selecting the right parser for your use case, you can more easily extract insights and value from your output data.\n\nWould you like to know more about a specific parser or how to use them in your projects?"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Stored Chat History ---\n",
            "Human: Hi! What is an output parser in LangChain?\n",
            "Ai: In LangChain, an output parser is a crucial component that helps extract relevant information from the output of a language model (LLM) or other AI tools. \n",
            "\n",
            "The primary function of an output parser is to take the raw output from an LLM, which can be unstructured or semi-structured text, and convert it into a more structured and usable format. This can include extracting specific entities, such as names, dates, or keywords, or identifying particular patterns or relationships within the text.\n",
            "\n",
            "Output parsers in LangChain are typically designed to be flexible and customizable, allowing developers to define their own parsing rules and logic to suit specific use cases or applications. By using output parsers, developers can more easily integrate LLMs into larger workflows or systems, and unlock the full potential of these powerful AI tools.\n",
            "\n",
            "Would you like to know more about how output parsers are used in LangChain or how to implement them in your own projects?\n",
            "Human: Why would I use StrOutputParser specifically?\n",
            "Ai: The `StrOutputParser` is a specific type of output parser in LangChain, and it's designed to parse string outputs from language models.\n",
            "\n",
            "You would use `StrOutputParser` when you want to extract information from a string output, such as a piece of text, a sentence, or a short paragraph. This parser is particularly useful when you need to:\n",
            "\n",
            "1. **Extract specific substrings**: For example, you might want to extract a specific keyword, phrase, or identifier from the output string.\n",
            "2. **Apply regular expressions**: `StrOutputParser` allows you to use regular expressions to match patterns in the output string, making it easy to extract complex information.\n",
            "3. **Split or tokenize the output**: You can use `StrOutputParser` to split the output string into individual tokens, such as words or phrases, which can be useful for further processing or analysis.\n",
            "\n",
            "The `StrOutputParser` is a simple yet powerful tool for extracting insights from string outputs. It's often used in conjunction with other LangChain components, such as agents or prompts, to build more complex workflows and applications.\n",
            "\n",
            "Is there a specific use case you're considering for `StrOutputParser`, or would you like more information on how to use it in your projects?\n",
            "Human: Are there other types of parsers? How are they different?\n",
            "Ai: In LangChain, there are several types of output parsers, each designed to handle different types of output data. Here are some examples:\n",
            "\n",
            "1. **StrOutputParser**: As we discussed earlier, this parser is designed to handle string outputs, such as text, sentences, or paragraphs.\n",
            "2. **JsonOutputParser**: This parser is used to handle JSON (JavaScript Object Notation) outputs, which are commonly used in web development and data exchange. `JsonOutputParser` allows you to extract specific data from JSON objects, such as keys, values, or nested structures.\n",
            "3. **DictOutputParser**: This parser is similar to `JsonOutputParser`, but it's designed to handle Python dictionaries (also known as dicts) instead of JSON objects. `DictOutputParser` is useful when working with outputs that are already in a dictionary format.\n",
            "4. **ListOutputParser**: As the name suggests, this parser is designed to handle list outputs, such as arrays of values or collections of items. `ListOutputParser` allows you to extract specific elements from the list, filter the list, or perform other operations.\n",
            "\n",
            "The main difference between these parsers is the type of output data they're designed to handle. Each parser has its own set of features and capabilities, tailored to the specific characteristics of the output data.\n",
            "\n",
            "When choosing a parser, consider the format and structure of the output data you're working with. For example:\n",
            "\n",
            "* If you're working with text outputs, `StrOutputParser` is a good choice.\n",
            "* If you're working with JSON data, `JsonOutputParser` is a better fit.\n",
            "* If you're working with Python dictionaries, `DictOutputParser` is the way to go.\n",
            "\n",
            "By selecting the right parser for your use case, you can more easily extract insights and value from your output data.\n",
            "\n",
            "Would you like to know more about a specific parser or how to use them in your projects?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c_knEWO28vBb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}