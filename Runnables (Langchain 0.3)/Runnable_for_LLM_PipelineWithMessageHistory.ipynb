{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmkH3ad+zlt4fMGSxwTGl8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["##LangChain Memory ‚Äì Theoretical Overview\n","\n","LangChain provides a variety of memory modules to help chains and agents **retain state or context across runs**. Each type is optimized for different scenarios and trade‚Äëoffs.\n","\n","---\n","\n","## 1. `SimpleMemory`\n","- **Purpose**: Store fixed context or static key-value data that **never changes** during sessions.\n","- **Use‚Äëcase**: Injecting static user profile, preferences, or configuration info into every prompt.\n","- **Main difference**: Immutable store; no temporal or conversational retention :contentReference[oaicite:0]{index=0}.\n","- **Note**: Not for conversation like memory for remembering previous question."],"metadata":{"id":"tQ7r8dQI6TOF"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4YQplk5T6CD7","executionInfo":{"status":"ok","timestamp":1750167151604,"user_tz":-330,"elapsed":24074,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}},"outputId":"f76cfa60-787c-4a11-fc5b-b94d7f500954"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/130.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# ====================================\n","# Step 1: Install Dependencies\n","# ====================================\n","!pip install -q langchain langchain-groq"]},{"cell_type":"code","source":["\n","# ====================================\n","# Step 2: Imports\n","# ====================================\n","from langchain_groq import ChatGroq\n","from langchain.prompts.chat import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n","from langchain.memory import SimpleMemory\n","from langchain_core.runnables import RunnableWithMessageHistory\n","from IPython.display import Markdown, display"],"metadata":{"id":"BkX4IyPf6Yj6","executionInfo":{"status":"ok","timestamp":1750167153387,"user_tz":-330,"elapsed":1779,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# ====================================\n","# Step 3: Setup Groq Chat LLM\n","# ====================================\n","from google.colab import userdata\n","api_key = userdata.get(\"GROQ_API_KEY\")  # or hardcode your API key\n","llm = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key=api_key)"],"metadata":{"id":"WZYFCc5J6bk1","executionInfo":{"status":"ok","timestamp":1750167376261,"user_tz":-330,"elapsed":2198,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# ====================================\n","# Step 4: Create a Prompt Template\n","# ====================================\n","system_msg = SystemMessagePromptTemplate.from_template(\n","    \"You are a helpful assistant. The user's name is {user_name} and they are a {user_role}. \"\n","    \"Always greet them by name and tailor responses based on their role.\"\n",")\n","\n","# üß† This is where memory will inject static user context\n","human_msg = HumanMessagePromptTemplate.from_template(\"{input}\")\n","prompt = ChatPromptTemplate.from_messages([\n","    system_msg,\n","    # MessagesPlaceholder(variable_name=\"history\"),  # Placeholder for memory\n","    human_msg\n","])"],"metadata":{"id":"cRj65YMO6bi1","executionInfo":{"status":"ok","timestamp":1750167376283,"user_tz":-330,"elapsed":7,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# ====================================\n","# Step 5: Setup SimpleMemory\n","# ====================================\n","memory = SimpleMemory(memories={\n","    \"user_name\": \"Dhruv\",\n","    \"user_role\": \"Data Scientist\"\n","})"],"metadata":{"id":"NPIeqltV6bgH","executionInfo":{"status":"ok","timestamp":1750167376285,"user_tz":-330,"elapsed":3,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# ====================================\n","# Step 6: Chain LLM + Prompt + Memory\n","# ====================================\n","chain = prompt | llm\n","\n","# Wrap with message history using memory\n","chat = RunnableWithMessageHistory(\n","    chain,\n","    lambda session_id: memory,\n","    input_messages_key=\"input\",\n","    history_messages_key=\"history\" # ChatMessageHistory handles this internally\n",")"],"metadata":{"id":"3qunyn3l6bdf","executionInfo":{"status":"ok","timestamp":1750167608591,"user_tz":-330,"elapsed":11,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# ====================================\n","#  Step 7: Ask Questions with SimpleMemory\n","# ====================================\n","user_inputs = [\n","    \"What can you help me with today?\",\n","    \"Give me advice on improving model accuracy.\",\n","]\n","\n","for input_text in user_inputs:\n","    prompt_input = {\n","        \"user_name\": memory.memories[\"user_name\"],\n","        \"user_role\": memory.memories[\"user_role\"],\n","        \"input\": input_text\n","    }\n","\n","    messages = prompt.format_messages(**prompt_input)\n","    response = llm.invoke(messages)\n","\n","    display(Markdown(f\"### ‚ùì User: {input_text}\"))\n","    display(Markdown(f\"**ü§ñ LLM Response:** {response.content}\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":703},"id":"YCXZdJYh6bax","executionInfo":{"status":"ok","timestamp":1750167772141,"user_tz":-330,"elapsed":3020,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}},"outputId":"bf71d354-053b-4799-df86-6f851e6e3386"},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### ‚ùì User: What can you help me with today?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**ü§ñ LLM Response:** Hello Dhruv, I'm glad you asked. As a Data Scientist, you likely work with complex data sets, models, and algorithms on a daily basis. I can assist you with a wide range of tasks, such as:\n\n* Providing explanations and examples of various machine learning concepts and techniques\n* Helping with data preprocessing, feature engineering, and data visualization\n* Offering guidance on model selection, hyperparameter tuning, and model evaluation\n* Discussing best practices for working with popular data science libraries and frameworks, such as Python, R, or SQL\n* Brainstorming ideas for tackling specific data science problems or projects\n* Even just being a sounding board for your ideas or helping you troubleshoot issues with your code\n\nWhat's on your mind today, Dhruv? Do you have a specific project or problem you'd like some help with?"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"### ‚ùì User: Give me advice on improving model accuracy."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Markdown object>"],"text/markdown":"**ü§ñ LLM Response:** Hello Dhruv, I hope you're doing well. As a Data Scientist, you're likely no stranger to the challenges of improving model accuracy. Here are some tips that might help:\n\n1. **Data Quality Check**: Ensure that your dataset is clean, complete, and consistent. Handling missing values, outliers, and data normalization can significantly impact model performance.\n2. **Feature Engineering**: Identify the most relevant features that contribute to the model's predictions. You can use techniques like correlation analysis, mutual information, or recursive feature elimination to select the best features.\n3. **Hyperparameter Tuning**: Perform grid search, random search, or Bayesian optimization to find the optimal hyperparameters for your model. This can be time-consuming, but it's often crucial for achieving better accuracy.\n4. **Model Selection**: Experiment with different algorithms and models to find the one that best suits your problem. Consider ensemble methods, such as bagging, boosting, or stacking, which can often improve accuracy.\n5. **Cross-Validation**: Use techniques like k-fold cross-validation to evaluate your model's performance on unseen data. This helps prevent overfitting and gives you a more realistic estimate of the model's accuracy.\n6. **Regularization**: Apply regularization techniques, such as L1 or L2 regularization, to prevent overfitting and improve the model's generalizability.\n7. **Ensemble Methods**: Combine the predictions of multiple models to improve overall accuracy. This can be particularly effective when dealing with complex datasets or noisy data.\n8. **Data Augmentation**: If you're working with image or text data, consider using data augmentation techniques to increase the size and diversity of your dataset.\n9. **Monitor Performance Metrics**: Track metrics like precision, recall, F1-score, and ROC-AUC to get a comprehensive understanding of your model's performance.\n10. **Iterate and Refine**: Continuously refine your model by iterating through these steps, and be willing to try new approaches and techniques to improve accuracy.\n\nRemember, Dhruv, improving model accuracy is often an iterative process that requires patience, persistence, and a deep understanding of the data and the problem you're trying to solve."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"F9b-rqh36bX4","executionInfo":{"status":"ok","timestamp":1750167379157,"user_tz":-330,"elapsed":28,"user":{"displayName":"Dhruv Sharma","userId":"05039836095185146849"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["### üß© Summary Table\n","\n","| Memory Type                   | Retention Style         | Use‚ÄëCase Scenario                              | Key Trade‚ÄëOffs                |\n","|------------------------------|--------------------------|------------------------------------------------|-------------------------------|\n","| `SimpleMemory`               | Static key-value         | System configs, user profile                  | No recall after changes       |\n","| `ConversationBufferMemory`   | Full chat transcript     | Small-scale chatbots                          | Token limits on long chats    |\n","| `ConversationSummaryMemory`  | Summarized history       | Extended multi-turn dialogues                 | Requires summarization LLM    |\n","| `VectorStoreRetrieverMemory` | Semantic retrieval       | Agents needing recollection from long history | Extra overhead, complexity    |\n","| `CombinedMemory`            | Composite memory         | Complex agents with varied memory needs       | Must manage & sync components |\n","\n","---\n","\n","## üß† Choosing the Right Memory\n","\n","- **Short conversations or testing** ‚Üí use `ConversationBufferMemory`\n","- **Extended sessions or long-term chatbots** ‚Üí use `ConversationSummaryMemory`\n","- **Hybrid pipelines needing static data + context** ‚Üí use `CombinedMemory`\n","- **Semantic retrieval over long history** ‚Üí use `VectorStoreRetrieverMemory`\n","- **Fixed metadata/config injection** ‚Üí use `SimpleMemory`\n"],"metadata":{"id":"u4lViWIJ7SW-"}},{"cell_type":"code","source":[],"metadata":{"id":"cn48W1-77Stt"},"execution_count":null,"outputs":[]}]}